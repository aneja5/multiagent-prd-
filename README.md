# Multi-Agent PRD Generator

A sophisticated tool that generates research-backed Product Requirements Documents (PRDs) using multiple AI agents coordinating through a shared state object. Built with the ReAct (Reasoning + Acting) framework.

## ğŸ‰ Day 3 Complete!

Three agents are live and collecting real research! Here's what's working:

- âœ… **ClarificationAgent** - Extracts structured metadata from product ideas
- âœ… **PlannerAgent** - Generates 15-20 domain-specific research queries
- âœ… **ResearcherAgent** - Executes queries and collects 50-80 evidence sources
- âœ… **Web Search** - Tavily API integration with caching
- âœ… **Content Extraction** - Jina Reader for clean markdown content
- âœ… **Credibility Scoring** - Domain, recency, and content quality signals
- âœ… **Evidence Deduplication** - MD5 + SimHash hybrid approach
- âœ… **DAG Orchestrator** - Manages task dependencies and agent sequencing
- âœ… **Test Suite** - 185+ passing tests
- â³ **SynthesisAgent** - Coming in Day 4
- â³ **PRDWriterAgent** - Coming in Day 5

## Overview

This tool transforms a simple product idea into a comprehensive PRD by:
- âœ… **Clarifying ambiguous requirements** through intelligent metadata extraction
- âœ… **Planning targeted research** with domain-specific queries and competitor analysis
- âœ… **Conducting web research** to gather 50-80 evidence sources per run
- âœ… **Scoring source credibility** based on domain, recency, and content quality
- â³ Analyzing competitors, pain points, and user workflows (Day 4)
- â³ Synthesizing findings into a well-structured PRD with citations (Day 5)

## Features

- **Multi-Agent Architecture**: Specialized agents work together to handle different aspects of PRD generation
- **ReAct Framework**: Each agent uses a Think-Act-Observe-Update-Reflect loop for intelligent decision-making
- **Research-Backed**: All claims in the PRD are backed by web research with proper citations
- **Stateful & Resumable**: Complete execution state is persisted, allowing runs to be paused and resumed
- **Production-Ready**: Comprehensive error handling, logging, retry logic, and type safety
- **Rich CLI**: Beautiful command-line interface with progress tracking and formatted output

### âœ… Research Execution (New in Day 3)

- **Web Search**: Tavily API integration (1,000 free searches/month)
- **Content Extraction**: Jina Reader for clean markdown from any URL
- **50-80 sources** collected per product idea
- **Source Credibility Scoring**:
  - Domain reputation (high: .gov, .edu, official docs)
  - Recency (newer content weighted higher)
  - Content quality signals (statistics, research, depth)
- **Evidence Typing**: article, forum, review, pricing, docs
- **Automatic Deduplication**: MD5 + SimHash for exact and near-duplicate detection
- **Smart Caching**: 24hr TTL to minimize API calls

## Current Architecture (Day 3)

```
User Input: "Build a HIPAA-compliant patient portal"
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DAG Orchestrator                         â”‚
â”‚  - Task dependency resolution                               â”‚
â”‚  - Agent scheduling & retry logic                           â”‚
â”‚  - State checkpointing after each agent                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Clarification    â”‚ â”‚   Planner        â”‚ â”‚   Researcher     â”‚
â”‚ Agent âœ…         â”‚ â”‚   Agent âœ…       â”‚ â”‚   Agent âœ…       â”‚
â”‚                  â”‚ â”‚                  â”‚ â”‚                  â”‚
â”‚ Extracts:        â”‚ â”‚ Generates:       â”‚ â”‚ Executes:        â”‚
â”‚ - domain         â”‚â†’â”‚ - 15-20 queries  â”‚â†’â”‚ - Web search     â”‚
â”‚ - industry_tags  â”‚ â”‚ - 4 categories   â”‚ â”‚ - Content fetch  â”‚
â”‚ - target_user    â”‚ â”‚ - priorities     â”‚ â”‚ - Credibility    â”‚
â”‚ - compliance     â”‚ â”‚ - sources        â”‚ â”‚ - Deduplication  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   Shared State   â”‚
                 â”‚                  â”‚
                 â”‚  âœ… metadata     â”‚
                 â”‚  âœ… research_planâ”‚
                 â”‚  âœ… evidence     â”‚  â† 50-80 sources
                 â”‚  â³ insights     â”‚
                 â”‚  â³ prd          â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
             Saved to: data/runs/{run_id}.json
```

## Evidence Quality

Our research collects high-quality, diverse sources:

**Source Distribution (typical run):**
- ğŸ“„ Articles: 35-45%
- ğŸ’¬ Forums (Reddit, HN, Stack Overflow): 20-30%
- â­ Reviews (G2, Capterra, TrustRadius): 15-20%
- ğŸ’° Pricing pages: 10-15%
- ğŸ“š Documentation: 5-10%

**Credibility Distribution:**
- ğŸŸ¢ High credibility: 20-30% (.gov, .edu, industry reports, official docs)
- ğŸŸ¡ Medium credibility: 50-60% (tech news, business sites, review platforms)
- ğŸ”´ Low credibility: 15-25% (forums, social media - still valuable for pain points!)

**Deduplication:**
- URL canonicalization (removes tracking params, www variants)
- MD5 hash for exact content matches
- SimHash for near-duplicate detection (paraphrased content)
- Fuzzy title matching (85% similarity threshold)

## Full Architecture (When Complete)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLI (main.py)                       â”‚
â”‚  - Parse arguments                                          â”‚
â”‚  - Initialize orchestrator                                  â”‚
â”‚  - Display results                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Orchestrator                             â”‚
â”‚  - Coordinate agent execution                               â”‚
â”‚  - Manage workflow                                          â”‚
â”‚  - Determine agent selection                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼               â–¼               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Clarify  â”‚   â”‚ Research â”‚   â”‚  PRD     â”‚
    â”‚  Agent   â”‚   â”‚  Agent   â”‚   â”‚  Writer  â”‚
    â”‚   âœ…     â”‚   â”‚   â³     â”‚   â”‚   â³     â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚              â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Shared State   â”‚
              â”‚                  â”‚
              â”‚  - Metadata      â”‚
              â”‚  - Research Plan â”‚
              â”‚  - Evidence      â”‚
              â”‚  - Insights      â”‚
              â”‚  - PRD           â”‚
              â”‚  - Task Board    â”‚
              â”‚  - Agent Trace   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Persistent      â”‚
              â”‚  Storage         â”‚
              â”‚  (JSON files)    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Start

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Set up environment
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY

# 3. Run your first PRD generation
python -m app.main "Build a project management tool for remote teams"

# 4. See the extracted metadata
# Output will show a formatted table with domain, industry tags, target user, etc.
```

## Usage Examples

### Generate a New PRD

```bash
# Basic usage
python -m app.main "Build a HIPAA-compliant patient portal"

# With verbose output (shows agent trace)
python -m app.main "AI-powered scheduling assistant" --verbose

# Short form
python -m app.main "Invoice tracking for freelancers" -v
```

**Output:**
```
âœ“ Clarification Complete
                       Extracted Metadata
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Field                â”ƒ Value                                  â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Domain               â”‚ healthcare                             â”‚
â”‚ Industry Tags        â”‚ patient_engagement, EMR, telehealth    â”‚
â”‚ Target User          â”‚ small medical clinics (2-10 providers) â”‚
â”‚ Geography            â”‚ US                                     â”‚
â”‚ Compliance           â”‚ HIPAA, state_medical_boards            â”‚
â”‚ Status               â”‚ pending                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### List All Runs

```bash
python -m app.main --list
```

### Resume an Existing Run

```bash
python -m app.main --resume <run-id>
```

### Inspect Evidence (New in Day 3)

```bash
# View all evidence from a run
python -m app.main --inspect <run-id>

# Filter by evidence type
python -m app.main --inspect <run-id> --type forum
python -m app.main --inspect <run-id> --type review

# Filter by credibility
python -m app.main --inspect <run-id> --credibility high

# View specific evidence details
python -m app.main --inspect <run-id> --evidence-id E5

# Combine filters
python -m app.main --inspect <run-id> --type docs --credibility high
```

### Run Tests

```bash
# Run all tests
pytest tests/ -v

# Run ClarificationAgent tests only
pytest tests/test_clarification.py -v

# Run with coverage
pytest tests/ --cov=app --cov=agents
```

## Project Structure

```
multiagent-prd/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # CLI interface âœ…
â”‚   â”œâ”€â”€ config.py            # Configuration management âœ…
â”‚   â”œâ”€â”€ logger.py            # Logging setup âœ…
â”‚   â”œâ”€â”€ state.py             # State schema and persistence âœ…
â”‚   â””â”€â”€ orchestrator.py      # DAG-based agent coordination âœ…
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_agent.py        # Base agent with ReAct framework âœ…
â”‚   â”œâ”€â”€ clarification.py     # ClarificationAgent âœ…
â”‚   â”œâ”€â”€ planner.py           # PlannerAgent âœ…
â”‚   â”œâ”€â”€ researcher.py        # ResearcherAgent âœ… (NEW)
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ clarification.txt # Clarification prompt âœ…
â”‚   â”‚   â”œâ”€â”€ planning.txt      # Planning prompt âœ…
â”‚   â”‚   â””â”€â”€ researcher.txt    # Research prompt (placeholder) âœ…
â”‚   â””â”€â”€ README.md            # Agent documentation âœ…
â”œâ”€â”€ tools/                   # Research tools (NEW)
â”‚   â”œâ”€â”€ __init__.py          # Package exports âœ…
â”‚   â”œâ”€â”€ web_search.py        # Tavily API integration âœ…
â”‚   â”œâ”€â”€ fetch_url.py         # Jina Reader content extraction âœ…
â”‚   â”œâ”€â”€ credibility.py       # Source credibility scoring âœ…
â”‚   â””â”€â”€ dedupe.py            # Evidence deduplication âœ…
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_clarification.py # ClarificationAgent tests (11) âœ…
â”‚   â”œâ”€â”€ test_planner.py       # PlannerAgent tests (26) âœ…
â”‚   â”œâ”€â”€ test_researcher.py    # ResearcherAgent tests (35) âœ…
â”‚   â”œâ”€â”€ test_web_search.py    # Web search tests (28) âœ…
â”‚   â”œâ”€â”€ test_fetch_url.py     # Content fetch tests (38) âœ…
â”‚   â”œâ”€â”€ test_credibility.py   # Credibility tests (38) âœ…
â”‚   â””â”€â”€ test_dedupe.py        # Deduplication tests (46) âœ…
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ runs/                # Saved run states (auto-created)
â”‚   â”œâ”€â”€ cache/               # API response cache (auto-created)
â”‚   â”‚   â”œâ”€â”€ search/          # Search results cache
â”‚   â”‚   â””â”€â”€ content/         # Fetched content cache
â”‚   â””â”€â”€ logs/                # Application logs (auto-created)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## Setup

### Prerequisites

- Python 3.9+
- OpenAI API key

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd multiagent-prd
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Configure environment variables:
```bash
cp .env.example .env
```

Edit `.env` and add your OpenAI API key:
```
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-2024-08-06
LOG_LEVEL=INFO
```

## Usage

### Start a New PRD Generation

```bash
python -m app.main "Build a project management tool for remote teams"
```

### Resume an Existing Run

```bash
python -m app.main --resume <run-id>
```

### List All Runs

```bash
python -m app.main --list
```

## State Schema

The system uses a comprehensive state schema that tracks all aspects of PRD generation:

```python
State {
    run_id: str                    # Unique run identifier
    created_at: str                # ISO timestamp
    status: "running|blocked|done" # Current status

    metadata: {
        raw_idea: str              # Original product idea
        domain: str                # Product domain
        industry_tags: [str]       # Industry classifications
        target_user: str           # Target audience
        geography: str             # Geographic focus
        compliance_contexts: [str] # Regulatory requirements
        prd_style: str            # Output format preference
        clarification_status: str  # Clarification state
    }

    research_plan: {
        queries: [Query]           # Research queries to execute
    }

    evidence: [Evidence]           # Collected research evidence
    insights: {
        pain_points: [PainPoint]   # Identified pain points
        competitors: [Competitor]  # Competitor analysis
        workflows: [Workflow]      # User workflows
    }

    prd: {
        sections: {}               # PRD content sections
        notion_markdown: str       # Formatted output
        citation_map: {}           # Evidence citations
    }

    task_board: [Task]            # Agent task management
    agent_trace: [AgentTraceEntry] # Execution history
}
```

## Agent Development

### Creating a New Agent

1. Create a new file in `agents/`:
```python
from agents.base_agent import BaseAgent
from app.state import State

class MyAgent(BaseAgent):
    def run(self, state: State) -> State:
        # 1. Think: Analyze state
        analysis = self._think(state)

        if not analysis["should_act"]:
            return state

        # 2. Act: Call LLM
        prompt = self._load_prompt()
        messages = [{"role": "user", "content": prompt}]
        response = self._call_llm(messages)

        # 3. Observe: Parse response
        observations = self._observe(response)

        # 4. Update: Modify state
        state = self._update_state(state, observations)

        # 5. Reflect: Log action
        self._log_action(state, "Completed my task")

        return state
```

2. Create a prompt template in `agents/prompts/my_agent.txt`

3. Register the agent in `app/main.py`:
```python
from agents.my_agent import MyAgent

orchestrator.register_agent(MyAgent("my_agent", client))
```

## Development Log

### ğŸ“… Day 1 (January 28-29, 2026) âœ… COMPLETE

**What Was Built:**
- âœ… Complete project foundation and scaffolding
- âœ… State management with Pydantic models and JSON persistence
- âœ… Configuration and logging infrastructure
- âœ… BaseAgent class with ReAct framework
- âœ… **ClarificationAgent** - Full implementation with:
  - Structured metadata extraction (domain, tags, users, compliance)
  - OpenAI structured output mode
  - 159-line prompt with 15-domain taxonomy and 5 few-shot examples
  - 11 comprehensive tests (all passing)
- âœ… CLI interface with Rich formatting
- âœ… Verbose mode for detailed agent traces
- âœ… Orchestrator with agent execution loop

**Key Achievements:**
- 349 lines of production-ready agent code
- Full test coverage for ClarificationAgent
- Beautiful table output for extracted metadata
- Fixed infinite loop bug in agent execution
- Complete documentation (agents/README.md, USAGE.md)

**Metrics:**
- Total LOC: ~3,500 lines
- Test Coverage: 11 tests, 100% passing
- API Cost per run: ~$0.01-0.02
- Execution Time: 2-5 seconds (clarification only)

---

### ğŸ“… Day 2 (January 29, 2026) âœ… COMPLETE

**What Was Built:**
- âœ… **PlannerAgent** - Full implementation with:
  - Domain-specific research query generation (15-20 queries per run)
  - 4 query categories: competitor, pain_points, workflow, compliance
  - Priority assignment (high/medium/low)
  - Expected sources tagging (forums, reviews, pricing_pages, etc.)
  - Post-processing for year markers and duplicate detection
  - 437-line prompt with domain-specific competitor lists
  - 26 comprehensive tests (all passing)
- âœ… **DAG Orchestrator** - Complete rewrite with:
  - Task dependency resolution
  - Agent registry with auto-discovery
  - State checkpointing after each agent
  - Retry logic with exponential backoff
- âœ… **Multi-domain testing** across 5 verticals:
  - Fintech (invoicing, expense tracking)
  - Healthcare (telemedicine, patient portals)
  - DevTools (security scanning, CI/CD)
  - Real Estate (CRM, property management)
  - Ecommerce (inventory, order management)

**Key Achievements:**
- 349 lines of PlannerAgent code
- 437-line prompt with 3 few-shot examples
- Query quality: 60-80% include year markers
- Fuzzy duplicate detection (80% threshold)
- All 37 tests passing

**Sample Output:**
```python
state.research_plan.queries = [
  Query(
    id="Q1",
    text="athenahealth vs Kareo pricing small practice 2024",
    category="competitor",
    priority="high",
    expected_sources=["pricing_pages", "comparison_sites"]
  ),
  Query(
    id="Q2",
    text="small clinic EHR implementation problems reddit",
    category="pain_points",
    priority="high",
    expected_sources=["forums"]
  ),
  # ... 13-18 more queries
]
```

---

### ğŸ“… Day 3 (February 2, 2026) âœ… COMPLETE

**What Was Built:**
- âœ… **ResearcherAgent** - Full implementation with:
  - Executes all queries from research plan
  - Collects 50-80 evidence sources per run
  - Parallel URL fetching (3 concurrent)
  - Rich progress bar with real-time status
  - Evidence type inference from URLs
  - 35 comprehensive tests (all passing)
- âœ… **Web Search Tool** (Tavily API):
  - Advanced search with domain filtering
  - Rate limiting (0.5s between requests)
  - Exponential backoff retry (3 attempts)
  - File-based caching (24hr TTL)
  - 28 tests (all passing)
- âœ… **Content Fetcher** (Jina Reader):
  - Clean markdown extraction from any URL
  - Smart truncation at sentence boundaries
  - Metadata extraction (title, author, date)
  - Caching (48hr TTL)
  - 38 tests (all passing)
- âœ… **Credibility Scorer**:
  - Domain reputation tiers (50+ high, 30+ medium, 15+ low)
  - Recency scoring (favors recent content)
  - Content quality signals (research, statistics, depth)
  - Spam/clickbait detection
  - 38 tests (all passing)
- âœ… **Evidence Deduplicator**:
  - URL canonicalization (tracking params, www, fragments)
  - MD5 hash for exact content matches
  - SimHash for near-duplicate detection
  - Fuzzy title matching (85% threshold)
  - 46 tests (all passing)
- âœ… **CLI Enhancements**:
  - `--inspect <run_id>` to view evidence
  - Filter by `--type` (article, forum, docs, etc.)
  - Filter by `--credibility` (high, medium, low)
  - View details with `--evidence-id E5`

**Key Achievements:**
- Full research pipeline: Idea â†’ Metadata â†’ Queries â†’ Evidence
- 185+ tests all passing
- 4 production-ready research tools
- Smart caching saves API calls
- Evidence ready for Day 4 analysis

**Metrics:**
- Total LOC: ~6,000+ lines
- Test Coverage: 185+ tests, 100% passing
- API Cost per run: ~$0.10-0.20 (search + content)
- Execution Time: 2-5 minutes (full research)

**Sample Evidence Output:**
```
Evidence Collected: 67 sources

By Type: {'article': 28, 'forum': 18, 'review': 12, 'pricing': 6, 'docs': 3}
By Credibility: {'high': 15, 'medium': 41, 'low': 11}

â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID  â”‚ Type    â”‚ Cred     â”‚ Title                                   â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ E1  â”‚ article â”‚ high     â”‚ Best Patient Scheduling Software 2024   â”‚
â”‚ E2  â”‚ review  â”‚ medium   â”‚ athenahealth vs Kareo - G2 Comparison   â”‚
â”‚ E3  â”‚ forum   â”‚ low      â”‚ HIPAA compliant messaging? : r/healthIT â”‚
â”‚ ... â”‚ ...     â”‚ ...      â”‚ ...                                     â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ“… Day 4 (TBD) - SynthesisAgent

**Planned:**
- [ ] SynthesisAgent implementation
- [ ] Analyze evidence and extract insights
- [ ] Identify pain points, competitors, workflows
- [ ] Populate `state.insights`

---

### ğŸ“… Day 5 (TBD) - PRDWriterAgent

**Planned:**
- [ ] PRDWriterAgent implementation
- [ ] Generate PRD sections with citations
- [ ] Notion markdown formatting
- [ ] Citation management
- [ ] Populate `state.prd`

---

## Development Roadmap

### Phase 1: Foundation âœ… COMPLETE
- [x] State schema and persistence
- [x] Configuration management
- [x] Logging infrastructure
- [x] Base agent with ReAct framework
- [x] CLI interface with Rich output
- [x] Orchestrator with agent execution
- [x] **ClarificationAgent** - Full implementation with tests

### Phase 2: Core Agents (Days 2-3) âœ… COMPLETE
- [x] Research Planner Agent âœ…
- [x] DAG-based Orchestrator âœ…
- [x] Web Search Tool (Tavily API) âœ…
- [x] Content Extraction (Jina Reader) âœ…
- [x] Credibility Scoring âœ…
- [x] Evidence Deduplication âœ…
- [x] **ResearcherAgent** - Full implementation with tests âœ…

### Phase 3: PRD Generation (Days 4-5)
- [ ] Insight Synthesis Agent
- [ ] PRD Writer Agent
- [ ] Citation Manager
- [ ] Quality Review Agent
- [ ] Notion Markdown Formatter

### Phase 4: Enhancements (Future)
- [ ] Parallel agent execution
- [ ] Advanced orchestration logic
- [ ] User interaction during execution
- [ ] Web UI
- [ ] Export formats (PDF, HTML)

## Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_API_KEY` | OpenAI API key (required) | - |
| `OPENAI_MODEL` | Model to use | `gpt-4o-2024-08-06` |
| `TAVILY_API_KEY` | Tavily search API key (required for research) | - |
| `JINA_API_KEY` | Jina Reader API key (optional, higher rate limits) | - |
| `LOG_LEVEL` | Logging level | `INFO` |
| `MAX_RETRIES` | API retry attempts | `3` |
| `RETRY_DELAY` | Delay between retries (seconds) | `1` |
| `OUTPUT_DIR` | Directory for run data | `data/runs` |
| `LOG_DIR` | Directory for logs | `data/logs` |

## Error Handling

The system includes comprehensive error handling:

- **API Errors**: Automatic retry with exponential backoff
- **Configuration Errors**: Clear error messages with resolution hints
- **State Persistence**: Atomic writes with validation
- **Agent Errors**: Logged and traced for debugging

## Logging

Logs are written to both console (with rich formatting) and file:

- Console: Colored output with timestamps
- File: `data/logs/app.log` with detailed information

## Testing

```bash
# Run all tests
pytest tests/ -v

# Run ClarificationAgent tests (11 tests, all passing âœ…)
pytest tests/test_clarification.py -v

# Run with coverage
pytest tests/ --cov=app --cov=agents --cov-report=html

# Run specific test
pytest tests/test_clarification.py::test_freelance_invoice_tool -v

# Type checking
mypy app/ agents/

# Code formatting
black app/ agents/
```

### Test Coverage (Day 3)

**Total: 185+ tests, all passing âœ…**

**ClarificationAgent** - 11 tests âœ…
- âœ… Metadata extraction across 5 domains
- âœ… Compliance detection (HIPAA, GDPR, SOC2)
- âœ… Error handling and retry logic

**PlannerAgent** - 26 tests âœ…
- âœ… Query generation (15-20 per run)
- âœ… Category distribution validation
- âœ… Duplicate detection and year markers

**ResearcherAgent** - 35 tests âœ…
- âœ… Query execution and evidence collection
- âœ… Type inference (article, forum, docs, pricing, review)
- âœ… State updates and task management
- âœ… Error handling for failed searches/fetches

**Web Search Tool** - 28 tests âœ…
- âœ… Tavily API integration
- âœ… Caching and rate limiting
- âœ… Retry with exponential backoff

**Content Fetcher** - 38 tests âœ…
- âœ… Jina Reader content extraction
- âœ… Smart truncation and metadata parsing
- âœ… Error handling and caching

**Credibility Scorer** - 38 tests âœ…
- âœ… Domain tier classification
- âœ… Recency and content quality scoring
- âœ… Spam/clickbait detection

**Evidence Deduplicator** - 46 tests âœ…
- âœ… URL canonicalization
- âœ… MD5 hash matching
- âœ… SimHash near-duplicate detection
- âœ… Fuzzy title matching

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes with proper type hints and docstrings
4. Add tests
5. Submit a pull request

## License

MIT License - see LICENSE file for details

## Support

For issues and questions:
- Open an issue on GitHub
- Check the documentation
- Review the agent trace logs for debugging

## Acknowledgments

Built with:
- OpenAI GPT-4
- Pydantic for data validation
- Rich for beautiful CLI output
- ReAct framework for agent reasoning
